{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import dill\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from extract_summary_finetune.model import lstm,transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict={\n",
    "    'lstm1':lstm,\n",
    "    'lstm2':lstm,\n",
    "    'lstm3':lstm,\n",
    "    'lstm4':lstm,   \n",
    "    'transformer1':transformer,\n",
    "    'transformer2':transformerimport sys\n",
    "import numpy as np\n",
    "from extract_summary_finetune.data import SummaryData,SummaryDataset\n",
    "import pytest\n",
    "\n",
    "def setup_module():\n",
    "    sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "class TestSummaryData():\n",
    "    \n",
    "    def setup_class(self):\n",
    "        for i in range(5):\n",
    "            a = np.random.randn(10,512,7) \n",
    "            b = np.random.randn(10,512)\n",
    "        np.savez(\"/home/yuxin.fan/data_for_test/file{}.npz\".format(i+1),a=a,b=b)\n",
    "\n",
    "        self.data = SummaryData(1,\"/home/yuxin.fan/data_for_test\")\n",
    "        self.data.divide_data() \n",
    "        \n",
    "    \n",
    "    def test_load_data(self):\n",
    "        token_data, label_data = self.data.load_data()\n",
    "        s1 = np.array(token_data).shape  \n",
    "        s2 = np.array(label_data).shape\n",
    "        assert ((s1==(5,10,512,7)*(s2==(5,10,512))))\n",
    "    \n",
    "    def test_divide_data(self): \n",
    "        train_dataset = self.data.train_token, self.data.train_label   #((40,512,7),(40,512))\n",
    "        test_dataset = self.data.test_token, self.data.test_label      #((10,512,7),(10,512))\n",
    "        INPUT_SIZE = self.data.input_size\n",
    "        TIME_STEP = self.data.time_step\n",
    "        s11 = train_dataset[0].shape  \n",
    "        s12 = train_dataset[1].shape\n",
    "        s21 = test_dataset[0].shape\n",
    "        s22 = test_dataset[1].shape \n",
    "        assert (type(train_dataset) == tuple)\n",
    "        assert (len(train_dataset) == 2)\n",
    "        assert (s11 == (40,512,7))\n",
    "        assert (s12 == (40,512))\n",
    "        assert (s21 == (10,512,7))\n",
    "        assert (s22 == (10,512))\n",
    "        assert (INPUT_SIZE == 7)\n",
    "        assert (TIME_STEP == 512)\n",
    "\n",
    "class TestSummaryData():\n",
    "    \n",
    "    def setup_class(self):\n",
    "        self.dataset = SummaryDataset(np.random.randn(3,5,7),np.random.randn(3,6,7))\n",
    " \n",
    "    def test_init_getitem_len(self):\n",
    "        T = self.dataset.token\n",
    "        L = self.dataset.label\n",
    "        x = self.dataset.token[1]\n",
    "        y = self.dataset.label[1]\n",
    "        s = self.dataset.token.shape[0]\n",
    "        assert(T.shape==(3,5,7))\n",
    "        assert(L.shape==(3,6,7))\n",
    "        assert(len(x)==5)\n",
    "        assert(len(y)==6)\n",
    "        assert(s==3)\n",
    "\n",
    "    'lstm1':{'input_size':1024, 'hidden_size':64, 'num_layers':1, 'dropout':0},\n",
    "}\n",
    "model_results_dict = {}\n",
    "pred_model_dict = {}\n",
    "model_list=['lstm1']\n",
    "for network in model_list:\n",
    "    file_name = f'summary_{network}.dil'\n",
    "    load_path =  os.path.join(\"/home/yuxin.fan/result/\",file_name)\n",
    "    with open(load_path, \"rb\") as file:\n",
    "        network_results_dict = dill.load(file)\n",
    "    model_results_dict[network] = network_results_dict\n",
    "    \n",
    "    \n",
    "    network_state_dict = network_results_dict['model_state_dict']\n",
    "    pred_network = model_dict[network](**model_setting_parameters[network])\n",
    "    pred_network.load_state_dict(network_state_dict, strict=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor1 = torch.tensor(np.load(\"/home/yuxin.fan/feature_from_swufe_bert.npy\",allow_pickle=True)).type(torch.float32)\n",
    "\n",
    "predict = pred_network(test_tensor1)\n",
    "predict = predict.ge(0.2)\n",
    "predict.type(torch.int)\n",
    "from extract_summary_finetune.performance_measures import calc_auc_score\n",
    "calc_auc_score(predict,predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         ...,\n",
      "         [False],\n",
      "         [False],\n",
      "         [False]],\n",
      "\n",
      "        [[ True],\n",
      "         [ True],\n",
      "         [ True],\n",
      "         ...,\n",
      "         [ True],\n",
      "         [ True],\n",
      "         [ True]]])\n",
      "[汽车之车官方获悉，特斯拉（中国）官网针对在售的Model S(参数|询价)长续航版、Performance高性能版的价格进行了下调，调整后售价为73.39万、83.39万元，降价幅度均为2.3万续航版的ND里6\n",
      "[汽车之家 新车上市] 日前，我们从官方获悉，特斯拉（中国）官网针对在售的Model S(参数|询价)长续航版、Performance高性能版的价格进行了下调，调整后售价为73.39万、83.39万元，降价幅度均为2.3万元。长续航版的NEDC续航里程为660km，0-100km加速时间为3.8秒；Performance高性能版0-100km加速时间仅为2.5秒。目前特斯拉（中国）官网显示的Model S共有三款车型，分别为长续航版、Performance 高性能版和Plaid版，此次调价仅针对前面两款车型。值得一提的是，特斯拉Model S的上一次调价是在7月份，全系车型下调幅度为0.8万元。今年5月份的调价幅度更大，特斯拉Model S全系车型售价下调了2.9万元。特斯拉Model S的整体造型设计并没有变化，动力同样没有发生改动，长续航版和Performance高性能版均搭载双电机，总最大功率分别为487千瓦、577千瓦，0-100km/h加速时间分别为3.8秒和2.5秒，二者的NEDC续航里程分别为660km、650km。（文/汽车之家 侯明浩）（责任编辑：王治强 HF013）。\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[汽车之车官方获悉，特斯拉（中国）官网针对在售的Model S(参数|询价)长续航版、Per...</td>\n",
       "      <td>[汽车之家 新车上市] 日前，我们从官方获悉，特斯拉（中国）官网针对在售的Model S(参...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>揭秘Siri，苹果发布论文阐释语音助手设计想法就多任务处理、多语言识别等问题，苹果在论文中给...</td>\n",
       "      <td>揭秘Siri，苹果发布论文阐释语音助手设计想法就多任务处理、多语言识别等问题，苹果在论文中给...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>在2018年的大牛行情过后，2019年的债市将如何演绎？多位基金经理在接受记者采访时表示，去...</td>\n",
       "      <td>在2018年的大牛行情过后，2019年的债市将如何演绎？多位基金经理在接受记者采访时表示，去...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>记者 ，总投资921亿元的广西“信息网”基础设施建设三年大会战正式启动。据了解，今年2月份，...</td>\n",
       "      <td>记者周骁骏 童政报道：日前，总投资921亿元的广西“信息网”基础设施建设三年大会战正式启动。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>从某种程度上来看，这是因为腾讯是一个强大的生态企业，而且有着诸多的现金奶牛业务，如我们熟悉的...</td>\n",
       "      <td>从某种程度上来看，这是因为腾讯是一个强大的生态企业，而且有着诸多的现金奶牛业务，如我们熟悉的...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>陇西县焦家湾村建起了别具特色的民俗文化墙，激发了贫困群众脱贫信心。”从甘肃陇西县城坐车20多...</td>\n",
       "      <td>陇西县焦家湾村建起了别具特色的民俗文化墙，激发了贫困群众脱贫信心。”从甘肃陇西县城坐车20多...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>近日，山东省文化和旅游厅印发《“好客服务”——全省旅游服务质量提升三年行动（2021-202...</td>\n",
       "      <td>近日，山东省文化和旅游厅印发《“好客服务”——全省旅游服务质量提升三年行动（2021-202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>”3月28日，位于孔子故里山东曲阜的孔子博物馆青少年活动中心，一场别开生面的“射柳”体验活动...</td>\n",
       "      <td>”3月28日，位于孔子故里山东曲阜的孔子博物馆青少年活动中心，一场别开生面的“射柳”体验活动...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>日前，记者从格兰仕顺德总部获悉，基于工业4.0、开源芯片两大科技项目的成熟推进与阶段性进展，...</td>\n",
       "      <td>日前，记者从格兰仕顺德总部获悉，基于工业4.0、开源芯片两大科技项目的成熟推进与阶段性进展，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>“党建联盟工程”助力脱贫攻坚。今年以来，贺州市平桂区以“围绕一个目标、探索一种组织设置、搭建...</td>\n",
       "      <td>“党建联盟工程”助力脱贫攻坚。今年以来，贺州市平桂区以“围绕一个目标、探索一种组织设置、搭建...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  [汽车之车官方获悉，特斯拉（中国）官网针对在售的Model S(参数|询价)长续航版、Per...   \n",
       "1  揭秘Siri，苹果发布论文阐释语音助手设计想法就多任务处理、多语言识别等问题，苹果在论文中给...   \n",
       "2  在2018年的大牛行情过后，2019年的债市将如何演绎？多位基金经理在接受记者采访时表示，去...   \n",
       "3  记者 ，总投资921亿元的广西“信息网”基础设施建设三年大会战正式启动。据了解，今年2月份，...   \n",
       "4  从某种程度上来看，这是因为腾讯是一个强大的生态企业，而且有着诸多的现金奶牛业务，如我们熟悉的...   \n",
       "5  陇西县焦家湾村建起了别具特色的民俗文化墙，激发了贫困群众脱贫信心。”从甘肃陇西县城坐车20多...   \n",
       "6  近日，山东省文化和旅游厅印发《“好客服务”——全省旅游服务质量提升三年行动（2021-202...   \n",
       "7  ”3月28日，位于孔子故里山东曲阜的孔子博物馆青少年活动中心，一场别开生面的“射柳”体验活动...   \n",
       "8  日前，记者从格兰仕顺德总部获悉，基于工业4.0、开源芯片两大科技项目的成熟推进与阶段性进展，...   \n",
       "9  “党建联盟工程”助力脱贫攻坚。今年以来，贺州市平桂区以“围绕一个目标、探索一种组织设置、搭建...   \n",
       "\n",
       "                                             content  \n",
       "0  [汽车之家 新车上市] 日前，我们从官方获悉，特斯拉（中国）官网针对在售的Model S(参...  \n",
       "1  揭秘Siri，苹果发布论文阐释语音助手设计想法就多任务处理、多语言识别等问题，苹果在论文中给...  \n",
       "2  在2018年的大牛行情过后，2019年的债市将如何演绎？多位基金经理在接受记者采访时表示，去...  \n",
       "3  记者周骁骏 童政报道：日前，总投资921亿元的广西“信息网”基础设施建设三年大会战正式启动。...  \n",
       "4  从某种程度上来看，这是因为腾讯是一个强大的生态企业，而且有着诸多的现金奶牛业务，如我们熟悉的...  \n",
       "5  陇西县焦家湾村建起了别具特色的民俗文化墙，激发了贫困群众脱贫信心。”从甘肃陇西县城坐车20多...  \n",
       "6  近日，山东省文化和旅游厅印发《“好客服务”——全省旅游服务质量提升三年行动（2021-202...  \n",
       "7  ”3月28日，位于孔子故里山东曲阜的孔子博物馆青少年活动中心，一场别开生面的“射柳”体验活动...  \n",
       "8  日前，记者从格兰仕顺德总部获悉，基于工业4.0、开源芯片两大科技项目的成熟推进与阶段性进展，...  \n",
       "9  “党建联盟工程”助力脱贫攻坚。今年以来，贺州市平桂区以“围绕一个目标、探索一种组织设置、搭建...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "content_data = []\n",
    "with open('/home/yuxin.fan/short_news_text1.txt','r',encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        content_data.append(line)\n",
    "content = content_data[0].strip('[]').strip('\\'').split('\\', \\'')\n",
    "content_filled = []\n",
    "for news in content:\n",
    "    #print(len(news))\n",
    "    if len(news) < 512:\n",
    "        news_filled = news+' '*(512 - len(news))\n",
    "        content_filled.append(news_filled)\n",
    "    else:\n",
    "        news_filled = news[:512]\n",
    "        content_filled.append(news_filled) \n",
    "    #print(len(news_filled)) \n",
    "content_word = [list(item) for item in content_filled]\n",
    "\n",
    "print(predict)\n",
    "summary = []\n",
    "for i in range(predict.shape[0]):\n",
    "    each_summary = ''\n",
    "    for j in range(predict.shape[1]):\n",
    "        each_summary= each_summary + (predict[i][j]*content_word[i][j])\n",
    "    summary.append(each_summary)\n",
    "\n",
    "print(summary[0])\n",
    "print(content[0])\n",
    "\n",
    "\n",
    "content_summary = pd.DataFrame.from_dict({'summary':summary,'content':content})\n",
    "content_summary.to_csv(\"/home/yuxin.fan/content_summary.csv\",index=False ,encoding='utf_8_sig')\n",
    "\n",
    "content_summary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((10,51,10))\n",
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be real number, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/yuxin.fan/extract_summary_finetune/note_book/summary_example.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.20.2.100/home/yuxin.fan/extract_summary_finetune/note_book/summary_example.ipynb#ch0000004vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.20.2.100/home/yuxin.fan/extract_summary_finetune/note_book/summary_example.ipynb#ch0000004vscode-remote?line=1'>2</a>\u001b[0m math\u001b[39m.\u001b[39;49mlog([\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m22\u001b[39;49m,\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,])\n",
      "\u001b[0;31mTypeError\u001b[0m: must be real number, not list"
     ]
    }
   ],
   "source": [
    "import math\n",
    "math.log([1,1,1,22,1,2,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= [1,8]\n",
    "for i in range(2):\n",
    "    a[i] = 1\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight1 = torch.tensor([[[0.7000],\n",
    "         [0.7000]],\n",
    "        [[0.3000],\n",
    "         [0.3000]]])\n",
    "\n",
    "weight2= torch.tensor([[[1.3000],\n",
    "         [0.7000]],\n",
    "        [[1.3000],\n",
    "         [0.7000]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[[0.5000],\n",
    "         [0.5000]],\n",
    "        [[0.0000],\n",
    "         [1.0000]]])\n",
    "\n",
    "targets = torch.tensor([[[1.0000],\n",
    "         [0.0000]],\n",
    "        [[0.0000],\n",
    "         [1.0000]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3466)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss()(inputs,targets.float())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2426)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss(weight=weight1)(inputs,targets.float())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3466)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss(weight=weight2)(inputs,targets.float())\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w= torch.tensor([[1,2],[3,4]],dtype=float)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000],\n",
       "         [1.0000]],\n",
       "\n",
       "        [[0.7737],\n",
       "         [1.2263]]], dtype=torch.float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extract_summary_finetune.loss_weighted import loss_weighted\n",
    "loss_weighted(inputs,targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3466)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.BCELoss(weight=loss_weighted(inputs,targets).float())(inputs,targets.float())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('swufe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa46084ac09a53b183332db73d934316dec080233f1a9b03c076216e26986b02"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
